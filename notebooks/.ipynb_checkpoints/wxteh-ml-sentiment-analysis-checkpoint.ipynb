{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b49e99b7-1b00-4e9e-95d4-921d9e091280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: googletrans==3.1.0a0 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (3.1.0a0)\n",
      "Requirement already satisfied: httpx==0.13.3 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from googletrans==3.1.0a0) (0.13.3)\n",
      "Requirement already satisfied: certifi in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.7.22)\n",
      "Requirement already satisfied: hstspreload in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.1.1)\n",
      "Requirement already satisfied: sniffio in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.0)\n",
      "Requirement already satisfied: chardet==3.* in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
      "Requirement already satisfied: idna==2.* in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpx==0.13.3->googletrans==3.1.0a0) (0.9.1)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0) (3.0.0)\n",
      "Collecting gensim\n",
      "  Obtaining dependency information for gensim from https://files.pythonhosted.org/packages/e8/d9/104988573fd2c1acdc64e66883b35fb8ae559310d2d9f77db78bf7de9add/gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from gensim) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages (from gensim) (1.11.2)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Obtaining dependency information for smart-open>=1.8.1 from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install nltk\n",
    "!pip3 install googletrans==3.1.0a0\n",
    "!pip3 install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b81d2a-2529-4fda-b57f-a214844df5ce",
   "metadata": {},
   "source": [
    "# Data Preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3669a72e-cea7-42e5-ac80-c0e8cebc7400",
   "metadata": {},
   "source": [
    "## Import Packages and Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e57bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from re import sub\n",
    "from time import time \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "#from unidecode import unidecode\n",
    "from collections import defaultdict\n",
    "from googletrans import Translator, constants\n",
    "\n",
    "# Packages for data preprocessing\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Gensim packages\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Packages for modelling\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ae83c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../raw_data/amazon.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1452145b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1465 entries, 0 to 1464\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   product_id           1465 non-null   object\n",
      " 1   product_name         1465 non-null   object\n",
      " 2   category             1465 non-null   object\n",
      " 3   discounted_price     1465 non-null   object\n",
      " 4   actual_price         1465 non-null   object\n",
      " 5   discount_percentage  1465 non-null   object\n",
      " 6   rating               1465 non-null   object\n",
      " 7   rating_count         1463 non-null   object\n",
      " 8   about_product        1465 non-null   object\n",
      " 9   user_id              1465 non-null   object\n",
      " 10  user_name            1465 non-null   object\n",
      " 11  review_id            1465 non-null   object\n",
      " 12  review_title         1465 non-null   object\n",
      " 13  review_content       1465 non-null   object\n",
      " 14  img_link             1465 non-null   object\n",
      " 15  product_link         1465 non-null   object\n",
      "dtypes: object(16)\n",
      "memory usage: 183.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9702838e-a87d-4738-a5a8-3f076571a2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'product_name', 'category', 'discounted_price',\n",
       "       'actual_price', 'discount_percentage', 'rating', 'rating_count',\n",
       "       'about_product', 'user_id', 'user_name', 'review_id', 'review_title',\n",
       "       'review_content', 'img_link', 'product_link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e761bcb-c2fa-469a-a6a3-0d999779dfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Computers&Accessories|Accessories&Peripherals|...\n",
       "1       Computers&Accessories|Accessories&Peripherals|...\n",
       "2       Computers&Accessories|Accessories&Peripherals|...\n",
       "3       Computers&Accessories|Accessories&Peripherals|...\n",
       "4       Computers&Accessories|Accessories&Peripherals|...\n",
       "                              ...                        \n",
       "1460    Home&Kitchen|Kitchen&HomeAppliances|WaterPurif...\n",
       "1461    Home&Kitchen|Kitchen&HomeAppliances|SmallKitch...\n",
       "1462    Home&Kitchen|Heating,Cooling&AirQuality|RoomHe...\n",
       "1463    Home&Kitchen|Heating,Cooling&AirQuality|Fans|E...\n",
       "1464    Home&Kitchen|Kitchen&HomeAppliances|SmallKitch...\n",
       "Name: category, Length: 1465, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96118a9e-b23f-4df8-8d9c-4118fe98f2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       4.2\n",
       "1       4.0\n",
       "2       3.9\n",
       "3       4.2\n",
       "4       4.2\n",
       "       ... \n",
       "1460      4\n",
       "1461    4.1\n",
       "1462    3.6\n",
       "1463      4\n",
       "1464    4.3\n",
       "Name: rating, Length: 1465, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22538300-b63c-489f-a3d2-5624e6b59e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id             0\n",
       "product_name           0\n",
       "category               0\n",
       "discounted_price       0\n",
       "actual_price           0\n",
       "discount_percentage    0\n",
       "rating                 0\n",
       "rating_count           2\n",
       "about_product          0\n",
       "user_id                0\n",
       "user_name              0\n",
       "review_id              0\n",
       "review_title           0\n",
       "review_content         0\n",
       "img_link               0\n",
       "product_link           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd456d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Computers&Accessories|Accessories&Peripherals|Cables&Accessories|Cables|USBCables'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_cat_rate = df.loc[:, ['category', 'rating','review_content']]\n",
    "df_review_cat_rate['category'] = df_review_cat_rate['category'].str.replace(',','|')\n",
    "df_review_cat_rate['category'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fb058e2-b959-4437-9cb5-e5ad5f16f21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a sample of the dataset (usb cables)\n",
    "df_review_cat_rate_sample = df_review_cat_rate[df_review_cat_rate['category'] == 'Computers&Accessories|Accessories&Peripherals|Cables&Accessories|Cables|USBCables']\n",
    "len(df_review_cat_rate_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0abef95f-b3a6-41a5-bf13-1d668687d035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7645/3131887549.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_cat_rate_sample[['cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5']] = df_review_cat_rate_sample['category'].str.split('|', expand=True)\n",
      "/tmp/ipykernel_7645/3131887549.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_cat_rate_sample[['cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5']] = df_review_cat_rate_sample['category'].str.split('|', expand=True)\n",
      "/tmp/ipykernel_7645/3131887549.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_cat_rate_sample[['cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5']] = df_review_cat_rate_sample['category'].str.split('|', expand=True)\n",
      "/tmp/ipykernel_7645/3131887549.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_cat_rate_sample[['cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5']] = df_review_cat_rate_sample['category'].str.split('|', expand=True)\n",
      "/tmp/ipykernel_7645/3131887549.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_review_cat_rate_sample[['cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5']] = df_review_cat_rate_sample['category'].str.split('|', expand=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_content</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>cat_4</th>\n",
       "      <th>cat_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Looks durable Charging is fine tooNo complains...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>Accessories&amp;Peripherals</td>\n",
       "      <td>Cables&amp;Accessories</td>\n",
       "      <td>Cables</td>\n",
       "      <td>USBCables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>I ordered this cable to connect my phone to An...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>Accessories&amp;Peripherals</td>\n",
       "      <td>Cables&amp;Accessories</td>\n",
       "      <td>Cables</td>\n",
       "      <td>USBCables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Not quite durable and sturdy,https://m.media-a...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>Accessories&amp;Peripherals</td>\n",
       "      <td>Cables&amp;Accessories</td>\n",
       "      <td>Cables</td>\n",
       "      <td>USBCables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Good product,long wire,Charges good,Nice,I bou...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>Accessories&amp;Peripherals</td>\n",
       "      <td>Cables&amp;Accessories</td>\n",
       "      <td>Cables</td>\n",
       "      <td>USBCables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Computers&amp;Accessories|Accessories&amp;Peripherals|...</td>\n",
       "      <td>4.2</td>\n",
       "      <td>Bought this instead of original apple, does th...</td>\n",
       "      <td>Computers&amp;Accessories</td>\n",
       "      <td>Accessories&amp;Peripherals</td>\n",
       "      <td>Cables&amp;Accessories</td>\n",
       "      <td>Cables</td>\n",
       "      <td>USBCables</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            category rating  \\\n",
       "0  Computers&Accessories|Accessories&Peripherals|...    4.2   \n",
       "1  Computers&Accessories|Accessories&Peripherals|...    4.0   \n",
       "2  Computers&Accessories|Accessories&Peripherals|...    3.9   \n",
       "3  Computers&Accessories|Accessories&Peripherals|...    4.2   \n",
       "4  Computers&Accessories|Accessories&Peripherals|...    4.2   \n",
       "\n",
       "                                      review_content                  cat_1  \\\n",
       "0  Looks durable Charging is fine tooNo complains...  Computers&Accessories   \n",
       "1  I ordered this cable to connect my phone to An...  Computers&Accessories   \n",
       "2  Not quite durable and sturdy,https://m.media-a...  Computers&Accessories   \n",
       "3  Good product,long wire,Charges good,Nice,I bou...  Computers&Accessories   \n",
       "4  Bought this instead of original apple, does th...  Computers&Accessories   \n",
       "\n",
       "                     cat_2               cat_3   cat_4      cat_5  \n",
       "0  Accessories&Peripherals  Cables&Accessories  Cables  USBCables  \n",
       "1  Accessories&Peripherals  Cables&Accessories  Cables  USBCables  \n",
       "2  Accessories&Peripherals  Cables&Accessories  Cables  USBCables  \n",
       "3  Accessories&Peripherals  Cables&Accessories  Cables  USBCables  \n",
       "4  Accessories&Peripherals  Cables&Accessories  Cables  USBCables  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the category column into multiple columns \n",
    "df_review_cat_rate_sample[['cat_1', 'cat_2', 'cat_3', 'cat_4', 'cat_5']] = df_review_cat_rate_sample['category'].str.split('|', expand=True)\n",
    "df_review_cat_rate_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f26c48-1962-4599-8842-7bdb4196bc0b",
   "metadata": {},
   "source": [
    "## Data Cleaning - SKIP THIS SECTION GO TO 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "749b5268-6442-4a3c-9bfa-1904ba4614f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split review columns to create additional rows, and fill category and average rating columns\n",
    "for i in df_review_cat_rate_sample:\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72c5bfff-a1ed-44ee-b7c5-17aabd696d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11503,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To see roughly how many revies we expect\n",
    "reviewers_user_id_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13f7638c-5dcc-4261-ac4e-9a278e7bf058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Value for money, with extra length👍'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting review content\n",
    "review_content_split = df[\"review_content\"].str.split(\",(?!\\s)\", expand=False).explode()\n",
    "review_content_clean = review_content_split.reset_index(drop=True)\n",
    "review_content_clean[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59e40b94-68b9-4d31-8aa2-c2d70544750d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12138,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_content_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c265b249-84b2-4d51-ad47-ec4aab5019be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looks durable Charging is fine tooNo complains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charging is really fast, good product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Till now satisfied with the quality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a good product . The charging speed is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good quality, would recommend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12133</th>\n",
       "      <td>Very good product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12134</th>\n",
       "      <td>This is a pretty powerful sandwich maker, for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12135</th>\n",
       "      <td>बोरोसिल ब्रांड का यह \"सेंडविच मेकर\" देखने में ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12136</th>\n",
       "      <td>Recommend work as expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12137</th>\n",
       "      <td>Its easy tp use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12138 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          review_content\n",
       "0         Looks durable Charging is fine tooNo complains\n",
       "1                 Charging is really fast, good product.\n",
       "2                   Till now satisfied with the quality.\n",
       "3      This is a good product . The charging speed is...\n",
       "4                          Good quality, would recommend\n",
       "...                                                  ...\n",
       "12133                                  Very good product\n",
       "12134  This is a pretty powerful sandwich maker, for ...\n",
       "12135  बोरोसिल ब्रांड का यह \"सेंडविच मेकर\" देखने में ...\n",
       "12136                         Recommend work as expected\n",
       "12137                                    Its easy tp use\n",
       "\n",
       "[12138 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_content_clean_df = pd.DataFrame(review_content_clean)\n",
    "review_content_clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bbe62e-ace6-4a74-97aa-add99d9b412e",
   "metadata": {},
   "source": [
    "## Translating non-English Reviews - SKIP THIS SECTION GO TO 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "44f10a2d-f534-4f86-a9f5-192237b995e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'बोरोसिल ब्रांड का यह \"सेंडविच मेकर\" देखने में तो अच्छा लगता है मगर इसकी बिल्ड क्वालिटी अच्छी नहीं है।  यह लगभग Rs 3000 के आसपास आता है।  इस प्रकार की बिल्ड क्वालिटी ₹2000 के करीब मिल जाती है तो कोई क्यों ₹1000 अधिक भुगतान करें।  पहले मैंने इसे review देखने के बाद ऑर्डर किया था लेकिन जब घर पर डिलीवरी होने के पश्चात  unboxing करके देखा तो इसकी बिल्ड क्वालिटी कुछ खास नहीं लगी इसलिए अपने पैसे बचाने के लिए मैंने इसे वापस भेज दिया। मैंने इसकी पैकेजिंग, मैनुअल और सैंडविच मेकर की फोटोग्राफ आप सभी से शेयर की है।  आप स्वयं देख के अनुमान लगा सकते हैं।'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_content_clean[12135]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d477fbe1-1a83-4c3a-9d5e-fedc291de00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           Looks durable Charging is fine tooNo complains\n",
       "1                   Charging is really fast, good product.\n",
       "2                     Till now satisfied with the quality.\n",
       "3        This is a good product . The charging speed is...\n",
       "4                            Good quality, would recommend\n",
       "                               ...                        \n",
       "12133                                    Very good product\n",
       "12134    This is a pretty powerful sandwich maker, for ...\n",
       "12135    बोरोसिल ब्रांड का यह \"सेंडविच मेकर\" देखने में ...\n",
       "12136                           Recommend work as expected\n",
       "12137                                      Its easy tp use\n",
       "Name: review_content, Length: 12138, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_content_clean_df[\"review_content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bf7d64e0-a3c2-4415-9eef-e8dc9b78d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = Translator()\n",
    "\n",
    "def translate_batch(text_batch):\n",
    "    translations = translator.translate(text_batch, dest=\"en\")\n",
    "    return [translation.text for translation in translations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15eeac35-c981-4944-9cab-14b9ad46a5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'batch_size = 100\\nfor i in range(0, len(review_content_clean_df), batch_size):\\n    batch = review_content_clean_df[\"review_content\"].iloc[i:i+batch_size].tolist()\\n    translated_batch = translate_batch(batch)\\n    review_content_clean_df[\"review_content\"].iloc[i:i+batch_size] = translated_batch'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''batch_size = 100\n",
    "for i in range(0, len(review_content_clean_df), batch_size):\n",
    "    batch = review_content_clean_df[\"review_content\"].iloc[i:i+batch_size].tolist()\n",
    "    translated_batch = translate_batch(batch)\n",
    "    review_content_clean_df[\"review_content\"].iloc[i:i+batch_size] = translated_batch'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b2ac5390-636a-47a3-8433-58b356b70d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Looks durable Charging is fine tooNo complains',\n",
       " 'Charging is really fast, good product.',\n",
       " 'Till now satisfied with the quality.',\n",
       " 'This is a good product . The charging speed is slower than the original iPhone cable',\n",
       " 'Good quality, would recommend',\n",
       " 'https://m.media-amazon.com/images/W/WEBP_402378-T1/images/I/81---F1ZgHL._SY88.jpg',\n",
       " 'Product had worked well till date and was having no issue.Cable is also sturdy enough...Have asked for replacement and company is doing the same...',\n",
       " 'Value for money',\n",
       " \"I ordered this cable to connect my phone to Android Auto of car. The cable is really strong and the connection ports are really well made. I already has a Micro USB cable from Ambrane and it's still in good shape. I connected my phone to the car using the cable and it got connected well and no issues. I also connected it to the charging port and yes it has Fast Charging support.\",\n",
       " \"It quality is good at this price and the main thing is that i didn't ever thought that this cable will be so long it's good one and charging power is too good and also supports fast charging\"]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_content_clean_translated = review_content_clean\n",
    "review_content_clean_translated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e417976",
   "metadata": {},
   "source": [
    "## Text Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9eb56dd1-e71e-4cda-be50-1a893b864258",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"../raw_data/reviews_cleaned.csv\"\n",
    "df_reviews= pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d757afc-c53b-4410-9b36-404a045a3014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Looks durable Charging is fine tooNo complains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charging is really fast, good product.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Till now satisfied with the quality.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a good product . The charging speed is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good quality, would recommend</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      review_content\n",
       "0     Looks durable Charging is fine tooNo complains\n",
       "1             Charging is really fast, good product.\n",
       "2               Till now satisfied with the quality.\n",
       "3  This is a good product . The charging speed is...\n",
       "4                      Good quality, would recommend"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bcc54e-e4bd-4646-ac2a-bf696bc84309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#review_str = [x for x in df_reviews['review_content'] if type(x) == str]\n",
    "#review_str[:10]\n",
    "df_reviews_dropna = df_reviews.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f685e1-3fb4-4fb1-b4ad-fe5dbd126f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_ml_old(sentence):\n",
    "    \n",
    "    sentence = sentence.strip() # remove whitespaces\n",
    "    sentence = sentence.lower() # lowercase \n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) # remove numbers\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    \n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize \n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "    \n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\") \n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "    \n",
    "    cleaned_sentence = ' '.join(word for word in lemmatized) # formed back the sentences\n",
    "    \n",
    "    return cleaned_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc63cea8-14b1-4ddd-b71a-b8b8adac1bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              look durable charge fine toono complain\n",
       "1                      charge really fast good product\n",
       "2                                 till satisfy quality\n",
       "3    good product charge speed slower original ipho...\n",
       "4                         good quality would recommend\n",
       "Name: review_content, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_content_clean_old = df_reviews_dropna['review_content'].apply(cleaning_ml_old)\n",
    "review_content_clean_old.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2ed9ccc-8e41-4a36-a514-0df8adbafb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_ml(sentence):\n",
    "    sentence = sentence.strip() # remove whitespaces\n",
    "    sentence = sentence.lower() # lowercase\n",
    "    sentence = ''.join(char for char in sentence if not char.isdigit()) # remove numbers\n",
    "    for punctuation in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation, '') ## remove punctuation\n",
    "    tokenized_sentence = word_tokenize(sentence) ## tokenize\n",
    "    stop_words = set(stopwords.words('english')) ## define stopwords\n",
    "    tokenized_sentence_cleaned = [ ## remove stopwords\n",
    "        w for w in tokenized_sentence if not w in stop_words\n",
    "    ]\n",
    "    lemmatized = [\n",
    "        WordNetLemmatizer().lemmatize(word, pos = \"v\")\n",
    "        for word in tokenized_sentence_cleaned\n",
    "    ]\n",
    "    return lemmatized  # Return a list of tokenized words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89009dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [look, durable, charge, fine, toono, complain]\n",
       "1                [charge, really, fast, good, product]\n",
       "2                             [till, satisfy, quality]\n",
       "3    [good, product, charge, speed, slower, origina...\n",
       "4                    [good, quality, would, recommend]\n",
       "Name: review_content, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review_content_clean_df[\"review_content_clean\"] = review_content_clean_df['review_content'].apply(lambda x:cleaning_ml(x))\n",
    "\n",
    "review_content_clean = df_reviews_dropna['review_content'].apply(cleaning_ml)\n",
    "review_content_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b1b5e5c-d71c-4edb-aa1f-205e7e705d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(review_content_clean_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440b683-3538-4bde-8686-179730e801db",
   "metadata": {},
   "source": [
    "# Tfidf Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31a87a4a-8b72-422b-a56f-7d13b6af6044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aacha</th>\n",
       "      <th>aachha</th>\n",
       "      <th>aage</th>\n",
       "      <th>aame</th>\n",
       "      <th>aamtech</th>\n",
       "      <th>aand</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapka</th>\n",
       "      <th>...</th>\n",
       "      <th>ನನ</th>\n",
       "      <th>ಪಸ</th>\n",
       "      <th>ರಣ</th>\n",
       "      <th>ಲಸ</th>\n",
       "      <th>ವಸ</th>\n",
       "      <th>ಸರ</th>\n",
       "      <th>ಹಣ</th>\n",
       "      <th>𝗔𝗱𝗵𝗲𝘀𝗶𝗼𝗻</th>\n",
       "      <th>𝗤𝘂𝗮𝗹𝗶𝘁𝘆</th>\n",
       "      <th>𝗳𝗼𝗿</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11008 rows × 13112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  aaa  aacha  aachha  aage  aame  aamtech  aand  aap  aapka  ...  \\\n",
       "0      0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "1      0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "2      0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "3      0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "4      0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "...    ...  ...    ...     ...   ...   ...      ...   ...  ...    ...  ...   \n",
       "11003  0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "11004  0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "11005  0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "11006  0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "11007  0.0  0.0    0.0     0.0   0.0   0.0      0.0   0.0  0.0    0.0  ...   \n",
       "\n",
       "        ನನ   ಪಸ   ರಣ   ಲಸ   ವಸ   ಸರ   ಹಣ  𝗔𝗱𝗵𝗲𝘀𝗶𝗼𝗻  𝗤𝘂𝗮𝗹𝗶𝘁𝘆  𝗳𝗼𝗿  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "4      0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...       ...      ...  ...  \n",
       "11003  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "11004  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "11005  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "11006  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "11007  0.0  0.0  0.0  0.0  0.0  0.0  0.0       0.0      0.0  0.0  \n",
       "\n",
       "[11008 rows x 13112 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "vectorized_reviews = vectorizer.fit_transform(review_content_clean_old)\n",
    "\n",
    "vectorized_reviews = pd.DataFrame(\n",
    "    vectorized_reviews.toarray(), \n",
    "    columns = vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "vectorized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae0a3b95-eda8-43ab-9a69-98c07e8e236d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(review_content_clean_old)\n",
    "features = pd.Series(tfidf.get_feature_names_out())\n",
    "transformed = tfidf.transform(review_content_clean_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0a1da2c-a831-41e9-b3ac-ea6e5d552464",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_content_list = review_content_clean_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93829fac-e4c6-4745-ab4c-888fec34c41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wxteh/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
    "tfidf.fit(review_content_list)\n",
    "features = pd.Series(tfidf.get_feature_names_out())\n",
    "transformed = tfidf.transform(review_content_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f39707ca-a4a4-4760-8b89-af3e9a61271c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse._csr.csr_matrix"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50b6a018-8f4a-415a-8858-c09b07de515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(index, transformed, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    vector_coo = transformed[index].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93240510-e4dc-40f0-b256-70a0026f0327",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_tfidf_words(index, review_content_list, transformed, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(index, transformed, features)   \n",
    "    review_content = review_content_list[index].split()\n",
    "    return [dictionary.get(word,0) for word in review_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdbb0b08-9cfa-43cf-a738-daca4ed3f711",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "5861",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 5861",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %%time\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#replaced_tfidf_scores = review_content_clean_old_df.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m replaced_tfidf_scores \u001b[38;5;241m=\u001b[39m [replace_tfidf_words(i, review_content_list, transformed, features) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(review_content_list))]\n",
      "Cell \u001b[0;32mIn[46], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# %%time\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#replaced_tfidf_scores = review_content_clean_old_df.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m replaced_tfidf_scores \u001b[38;5;241m=\u001b[39m [\u001b[43mreplace_tfidf_words\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreview_content_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(review_content_list))]\n",
      "Cell \u001b[0;32mIn[45], line 9\u001b[0m, in \u001b[0;36mreplace_tfidf_words\u001b[0;34m(index, review_content_list, transformed, features)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mreplacing each word with it's calculated tfidf dictionary with scores of each word\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03mx - row of dataframe, containing sentences, and their indexes,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124;03mtransformed_file - all sentences transformed with TfidfVectorizer\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03mfeatures - names of all words in corpus used in TfidfVectorizer\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dictionary \u001b[38;5;241m=\u001b[39m create_tfidf_dictionary(index, transformed, features)   \n\u001b[0;32m----> 9\u001b[0m review_content \u001b[38;5;241m=\u001b[39m \u001b[43mreview_content_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [dictionary\u001b[38;5;241m.\u001b[39mget(word,\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m review_content]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/amazon-customer-review-analysis/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 5861"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "#replaced_tfidf_scores = review_content_clean_old_df.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)\n",
    "\n",
    "replaced_tfidf_scores = [replace_tfidf_words(i, review_content_list, transformed, features) for i in range(len(review_content_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4d9ea3d-bc7c-4208-ab93-318fc7eb4153",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replaced_tfidf_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replaced_tfidf_scores \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(\u001b[43mreplaced_tfidf_scores\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mtype\u001b[39m(replaced_tfidf_scores)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'replaced_tfidf_scores' is not defined"
     ]
    }
   ],
   "source": [
    "replaced_tfidf_scores = pd.Series(replaced_tfidf_scores)\n",
    "type(replaced_tfidf_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da49fbb-970c-4827-aa76-b0cb78d48baa",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Word2Vec, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abdd9ccc-40ff-43bb-91af-20c711e02a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x7f8797387790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = Phrases(review_content_clean, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "reviews = bigram[review_content_clean]\n",
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6854379-5cb8-407a-ae2f-a8b5574a9a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.01 mins\n",
      "Time to train the model: 0.29 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24370/667237732.py:15: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('comfort', 0.9998939037322998),\n",
       " ('capability', 0.9998906850814819),\n",
       " ('restrict', 0.9998897314071655),\n",
       " ('powerful', 0.9998894333839417),\n",
       " ('firm', 0.9998886585235596),\n",
       " ('break_fall', 0.9998874664306641),\n",
       " ('question', 0.9998863935470581),\n",
       " ('sit', 0.9998855590820312),\n",
       " ('several', 0.9998852610588074),\n",
       " ('opinion', 0.9998851418495178),\n",
       " ('rotate', 0.9998836517333984),\n",
       " ('absolute', 0.9998836517333984),\n",
       " ('apt', 0.9998835921287537),\n",
       " ('maintain', 0.9998835325241089),\n",
       " ('spoil', 0.9998833537101746),\n",
       " ('modify', 0.9998833537101746),\n",
       " ('glossy', 0.9998831152915955),\n",
       " ('generator', 0.999882698059082),\n",
       " ('coffee_powder', 0.9998825192451477),\n",
       " ('domestic', 0.9998824596405029)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "start = time()\n",
    "w2v_model.build_vocab(reviews, progress_per=50000)\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "start = time()\n",
    "w2v_model.train(reviews, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "w2v_model.init_sims(replace=True)\n",
    "word_vectors = w2v_model.wv\n",
    "word_vectors\n",
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))\n",
    "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=20, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26489884-8f59-4519-81a0-f7d72c0d6eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x7f8751e77ca0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sent = [row for row in review_content_clean_old.review_content] #this step is used to break down the sentences into individual words separate by commas (skipping this as this has been done in the function above)\n",
    "phrases = Phrases(review_content_clean, min_count=1, progress_per=50) # what is progress_per argument\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[review_content_clean]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "454a51cd-a487-4519-ab1e-0682ce80a645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.01 mins\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db9b0319-f20a-460b-b6a3-feeec15eaa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.63 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24370/397523926.py:7: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
    "\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4bf43ffb-13b0-4abc-a216-ae6eef54bc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec_test.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e8011f4-9584-4912-adc4-bb33cfc78205",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"../notebooks/word2vec_test.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b374990e-50ca-48ca-93ac-951549ad98e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "km_model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01ec097b-2fa8-45bd-8593-ad6ef8841116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('greater_ever', 0.3830764889717102),\n",
       " ('fathful', 0.37170109152793884),\n",
       " ('pover_quality', 0.34164655208587646),\n",
       " ('storage_perfect', 0.3286029100418091),\n",
       " ('nil', 0.3196718692779541),\n",
       " ('exllent', 0.31487852334976196),\n",
       " ('connectivity_faster', 0.31339526176452637),\n",
       " ('rejonabule_price', 0.2724839150905609),\n",
       " ('reliable_worth', 0.2322179675102234),\n",
       " ('look_fake', -0.14544925093650818)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(km_model.cluster_centers_[1], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b6fcec1-8faf-493b-a10d-7ec9feed668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_index = 1\n",
    "positive_cluster_center = km_model.cluster_centers_[positive_cluster_index]\n",
    "negative_cluster_center = km_model.cluster_centers_[1-positive_cluster_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f86ca93b-5032-415c-bbd7-5bfb862dfa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.index_to_key)\n",
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: km_model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b23f72a-9f2c-4e97-8d4f-debf337c6fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(km_model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "745530a4-8d71-438b-bf81-17e5b5a943b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>good</td>\n",
       "      <td>[-0.024528792, -0.01203786, 0.001923861, 0.011...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>45.755804</td>\n",
       "      <td>-45.755804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>product</td>\n",
       "      <td>[-0.02466261, -0.009491598, 0.00018095183, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.810572</td>\n",
       "      <td>-46.810572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>use</td>\n",
       "      <td>[-0.0232638, -0.01265904, -0.00063081976, 0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.743654</td>\n",
       "      <td>-46.743654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quality</td>\n",
       "      <td>[-0.02582756, -0.013222651, -0.0012275213, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>50.365790</td>\n",
       "      <td>-50.365790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cable</td>\n",
       "      <td>[-0.026153559, -0.011780159, 0.002263465, 0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>34.296287</td>\n",
       "      <td>-34.296287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>get</td>\n",
       "      <td>[-0.024903169, -0.010827062, 0.0016263425, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>42.087392</td>\n",
       "      <td>-42.087392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>like</td>\n",
       "      <td>[-0.02202192, -0.013174913, 0.00010001566, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>52.217693</td>\n",
       "      <td>-52.217693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>work</td>\n",
       "      <td>[-0.024047634, -0.010946075, 0.002131802, 0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>48.470905</td>\n",
       "      <td>-48.470905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>one</td>\n",
       "      <td>[-0.025660053, -0.010697496, 0.0009751191, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.898113</td>\n",
       "      <td>-46.898113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>buy</td>\n",
       "      <td>[-0.024003675, -0.010926574, -0.0009035432, 0....</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>46.611172</td>\n",
       "      <td>-46.611172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     words                                            vectors  cluster  \\\n",
       "0     good  [-0.024528792, -0.01203786, 0.001923861, 0.011...        0   \n",
       "1  product  [-0.02466261, -0.009491598, 0.00018095183, 0.0...        0   \n",
       "2      use  [-0.0232638, -0.01265904, -0.00063081976, 0.01...        0   \n",
       "3  quality  [-0.02582756, -0.013222651, -0.0012275213, 0.0...        0   \n",
       "4    cable  [-0.026153559, -0.011780159, 0.002263465, 0.00...        0   \n",
       "5      get  [-0.024903169, -0.010827062, 0.0016263425, 0.0...        0   \n",
       "6     like  [-0.02202192, -0.013174913, 0.00010001566, 0.0...        0   \n",
       "7     work  [-0.024047634, -0.010946075, 0.002131802, 0.01...        0   \n",
       "8      one  [-0.025660053, -0.010697496, 0.0009751191, 0.0...        0   \n",
       "9      buy  [-0.024003675, -0.010926574, -0.0009035432, 0....        0   \n",
       "\n",
       "   cluster_value  closeness_score  sentiment_coeff  \n",
       "0             -1        45.755804       -45.755804  \n",
       "1             -1        46.810572       -46.810572  \n",
       "2             -1        46.743654       -46.743654  \n",
       "3             -1        50.365790       -50.365790  \n",
       "4             -1        34.296287       -34.296287  \n",
       "5             -1        42.087392       -42.087392  \n",
       "6             -1        52.217693       -52.217693  \n",
       "7             -1        48.470905       -48.470905  \n",
       "8             -1        46.898113       -46.898113  \n",
       "9             -1        46.611172       -46.611172  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fedb23b-e8cc-4e9a-aab7-5b965d55064b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = words.set_index('words')['sentiment_coeff'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54cb5d3a-f389-4603-aceb-923a9063d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7938"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b0fd59-c1d2-40a5-9753-3238e7df1ed4",
   "metadata": {},
   "source": [
    "# Sentiment Result: Combining Tfidf score and Word2Vec + K-Means Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12b0d9a4-f5b4-4524-9991-989ca3956c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "42da1c3a-afc9-4485-93a0-07539d13b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = review_content_list.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "861dfb0d-f436-4396-8b64-a2d11cb3ce36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [-51.27189252540009, -59.131524302100736, -36....\n",
       "1        [-36.262249365830016, -53.216129467317266, -53...\n",
       "2        [-53.76406151495599, -39.921529775082014, -50....\n",
       "3        [-45.755804070599446, -46.81057247227709, -36....\n",
       "4        [-45.755804070599446, -50.365790379336836, -52...\n",
       "                               ...                        \n",
       "11007            [-45.755804070599446, -46.81057247227709]\n",
       "11008    [-55.68330973974188, -68.89479214193429, -58.2...\n",
       "11009    [-58.25874436711506, -51.15998218485107, -55.0...\n",
       "11010    [-59.306449151573545, -48.47090461571889, -56....\n",
       "11011    [-56.09848330510211, -53.95570159801775, -46.7...\n",
       "Name: review_content, Length: 11008, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_closeness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96b12bae-1f88-4836-8fcc-023d7d447a40",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replaced_tfidf_scores' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m replacement_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39m[replaced_closeness_scores, \u001b[43mreplaced_tfidf_scores\u001b[49m, review_content_list])\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      2\u001b[0m replacement_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_coeff\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentence\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m replacement_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_rate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m replacement_df\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39marray(x\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment_coeff\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m@\u001b[39m np\u001b[38;5;241m.\u001b[39marray(x\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtfidf_scores\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'replaced_tfidf_scores' is not defined"
     ]
    }
   ],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, review_content_list]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4de5020f-c53d-475f-aa77-06d01dafbaba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replacement_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mreplacement_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'replacement_df' is not defined"
     ]
    }
   ],
   "source": [
    "replacement_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d0bb48-d340-4716-ad49-7a653d547a0d",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fa58cb-c243-4aae-b02b-02822b8c28f8",
   "metadata": {},
   "source": [
    "# Topic Modelling: Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8336e48e-4cb1-4936-bebe-7bda657017f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LatentDirichletAllocation(max_iter=100, n_components=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LatentDirichletAllocation</label><div class=\"sk-toggleable__content\"><pre>LatentDirichletAllocation(max_iter=100, n_components=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LatentDirichletAllocation(max_iter=100, n_components=5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate the LDA \n",
    "n_components = 5\n",
    "lda_model = LatentDirichletAllocation(n_components=n_components, max_iter = 100)\n",
    "\n",
    "# Fit the LDA on the vectorized documents\n",
    "lda_model.fit(vectorized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ecaab599-76f0-4757-a95b-f7a2d9f20d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "reviews_topic = lda_model.transform(vectorized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bdaedc9-8baf-4875-b5d2-1e3aa85d4816",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aacha</th>\n",
       "      <th>aachha</th>\n",
       "      <th>aage</th>\n",
       "      <th>aame</th>\n",
       "      <th>aamtech</th>\n",
       "      <th>aand</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapka</th>\n",
       "      <th>...</th>\n",
       "      <th>ನನ</th>\n",
       "      <th>ಪಸ</th>\n",
       "      <th>ರಣ</th>\n",
       "      <th>ಲಸ</th>\n",
       "      <th>ವಸ</th>\n",
       "      <th>ಸರ</th>\n",
       "      <th>ಹಣ</th>\n",
       "      <th>𝗔𝗱𝗵𝗲𝘀𝗶𝗼𝗻</th>\n",
       "      <th>𝗤𝘂𝗮𝗹𝗶𝘁𝘆</th>\n",
       "      <th>𝗳𝗼𝗿</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.523487</td>\n",
       "      <td>0.222282</td>\n",
       "      <td>0.690251</td>\n",
       "      <td>0.200877</td>\n",
       "      <td>0.200070</td>\n",
       "      <td>0.200072</td>\n",
       "      <td>0.200084</td>\n",
       "      <td>0.200046</td>\n",
       "      <td>0.201581</td>\n",
       "      <td>0.457633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200025</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200025</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200025</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>0.200034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.222634</td>\n",
       "      <td>1.335476</td>\n",
       "      <td>0.200052</td>\n",
       "      <td>0.200398</td>\n",
       "      <td>0.250423</td>\n",
       "      <td>0.335992</td>\n",
       "      <td>0.441166</td>\n",
       "      <td>0.200470</td>\n",
       "      <td>0.200007</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>0.200003</td>\n",
       "      <td>0.200004</td>\n",
       "      <td>0.209926</td>\n",
       "      <td>0.209926</td>\n",
       "      <td>0.209926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.200188</td>\n",
       "      <td>0.200054</td>\n",
       "      <td>0.200016</td>\n",
       "      <td>0.505249</td>\n",
       "      <td>0.200027</td>\n",
       "      <td>0.200053</td>\n",
       "      <td>0.200065</td>\n",
       "      <td>0.200550</td>\n",
       "      <td>0.588634</td>\n",
       "      <td>0.200161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.200013</td>\n",
       "      <td>0.200018</td>\n",
       "      <td>0.200025</td>\n",
       "      <td>0.200025</td>\n",
       "      <td>0.200025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.200914</td>\n",
       "      <td>0.200157</td>\n",
       "      <td>0.200012</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>0.200039</td>\n",
       "      <td>0.200061</td>\n",
       "      <td>0.200071</td>\n",
       "      <td>0.854442</td>\n",
       "      <td>0.200033</td>\n",
       "      <td>0.200212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388903</td>\n",
       "      <td>0.577907</td>\n",
       "      <td>0.388903</td>\n",
       "      <td>0.577907</td>\n",
       "      <td>0.577907</td>\n",
       "      <td>0.577907</td>\n",
       "      <td>0.388903</td>\n",
       "      <td>0.200030</td>\n",
       "      <td>0.200030</td>\n",
       "      <td>0.200030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.200072</td>\n",
       "      <td>0.200089</td>\n",
       "      <td>0.200519</td>\n",
       "      <td>0.200031</td>\n",
       "      <td>0.200049</td>\n",
       "      <td>0.200087</td>\n",
       "      <td>0.200101</td>\n",
       "      <td>0.200056</td>\n",
       "      <td>0.200047</td>\n",
       "      <td>0.200021</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200031</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>0.200031</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>0.200023</td>\n",
       "      <td>0.200031</td>\n",
       "      <td>0.356229</td>\n",
       "      <td>0.356229</td>\n",
       "      <td>0.356229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aa       aaa     aacha    aachha      aage      aame   aamtech  \\\n",
       "0  1.523487  0.222282  0.690251  0.200877  0.200070  0.200072  0.200084   \n",
       "1  2.222634  1.335476  0.200052  0.200398  0.250423  0.335992  0.441166   \n",
       "2  0.200188  0.200054  0.200016  0.505249  0.200027  0.200053  0.200065   \n",
       "3  0.200914  0.200157  0.200012  0.200021  0.200039  0.200061  0.200071   \n",
       "4  0.200072  0.200089  0.200519  0.200031  0.200049  0.200087  0.200101   \n",
       "\n",
       "       aand       aap     aapka  ...        ನನ        ಪಸ        ರಣ        ಲಸ  \\\n",
       "0  0.200046  0.201581  0.457633  ...  0.200025  0.200018  0.200025  0.200018   \n",
       "1  0.200470  0.200007  0.200003  ...  0.200004  0.200003  0.200004  0.200003   \n",
       "2  0.200550  0.588634  0.200161  ...  0.200018  0.200013  0.200018  0.200013   \n",
       "3  0.854442  0.200033  0.200212  ...  0.388903  0.577907  0.388903  0.577907   \n",
       "4  0.200056  0.200047  0.200021  ...  0.200031  0.200023  0.200031  0.200023   \n",
       "\n",
       "         ವಸ        ಸರ        ಹಣ  𝗔𝗱𝗵𝗲𝘀𝗶𝗼𝗻   𝗤𝘂𝗮𝗹𝗶𝘁𝘆       𝗳𝗼𝗿  \n",
       "0  0.200018  0.200018  0.200025  0.200034  0.200034  0.200034  \n",
       "1  0.200003  0.200003  0.200004  0.209926  0.209926  0.209926  \n",
       "2  0.200013  0.200013  0.200018  0.200025  0.200025  0.200025  \n",
       "3  0.577907  0.577907  0.388903  0.200030  0.200030  0.200030  \n",
       "4  0.200023  0.200023  0.200031  0.356229  0.356229  0.356229  \n",
       "\n",
       "[5 rows x 13112 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_list = pd.DataFrame(\n",
    "    lda_model.components_, \n",
    "    columns = vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "topic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "302a5e42-0a1c-4cb1-bdf8-6356c5d889a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topics(lda_model, vectorizer, top_words):\n",
    "    # 1. TOPIC MIXTURE OF WORDS FOR EACH TOPIC\n",
    "    topic_mixture = pd.DataFrame(\n",
    "        lda_model.components_,\n",
    "        columns = vectorizer.get_feature_names_out()\n",
    "    )\n",
    "    \n",
    "    # 2. FINDING THE TOP WORDS FOR EACH TOPIC\n",
    "    ## Number of topics\n",
    "    n_components = topic_mixture.shape[0]\n",
    "\n",
    "    ## Top words for each topic\n",
    "    for topic in range(n_components):\n",
    "        print(\"-\"*10)\n",
    "        print(f\"For topic {topic}, here are the the top {top_words} words with weights:\")\n",
    "\n",
    "        topic_df = topic_mixture.iloc[topic]\\\n",
    "            .sort_values(ascending = False).head(top_words)\n",
    "        \n",
    "        print(round(topic_df,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bcdb0891-228d-4b4f-8807-ca73f1afb7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "For topic 0, here are the the top 5 words with weights:\n",
      "charge     124.712\n",
      "fast        82.204\n",
      "cable       73.240\n",
      "durable     34.426\n",
      "sturdy      29.806\n",
      "Name: 0, dtype: float64\n",
      "----------\n",
      "For topic 1, here are the the top 5 words with weights:\n",
      "nice       428.328\n",
      "product    311.732\n",
      "good       280.814\n",
      "work       256.817\n",
      "use        246.388\n",
      "Name: 1, dtype: float64\n",
      "----------\n",
      "For topic 2, here are the the top 5 words with weights:\n",
      "good       1008.778\n",
      "product     393.044\n",
      "quality     186.277\n",
      "easy         97.336\n",
      "price        95.081\n",
      "Name: 2, dtype: float64\n",
      "----------\n",
      "For topic 3, here are the the top 5 words with weights:\n",
      "money    216.001\n",
      "value    200.490\n",
      "like     160.458\n",
      "ok       144.208\n",
      "worth     80.924\n",
      "Name: 3, dtype: float64\n",
      "----------\n",
      "For topic 4, here are the the top 5 words with weights:\n",
      "super      41.221\n",
      "go         30.357\n",
      "satisfy    29.638\n",
      "till       13.007\n",
      "dislike    12.712\n",
      "Name: 4, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print_topics(lda_model, vectorizer, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0f42a0-0e81-45c7-91b4-c149c82f61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Apply translation data clean by Arthur\n",
    "### Split the dataset by categories and split into (using average reviews) 1,2,3 (bad products) and 4,5 (good products)\n",
    "### Run LDA model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4605f2af-c52f-4b6c-9ff3-e58976fdd7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
